#!/usr/bin/env python3
"""
–û–ø—Ç–∏–º—ñ–∑–æ–≤–∞–Ω–∏–π —Å–∫—Ä–∏–ø—Ç –¥–ª—è —Ç–µ—Å—Ç—É–≤–∞–Ω–Ω—è –ø—Ä–æ–¥—É–∫—Ç–∏–≤–Ω–æ—Å—Ç—ñ YOLO –º–æ–¥–µ–ª—ñ –Ω–∞ –≤—ñ–¥–µ–æ
–ú–∞–∫—Å–∏–º–∞–ª—å–Ω–æ –æ–ø—Ç–∏–º—ñ–∑–æ–≤–∞–Ω–∏–π –¥–ª—è —à–≤–∏–¥–∫–æ—Å—Ç—ñ –±–µ–∑ –≤—ñ–∑—É–∞–ª—ñ–∑–∞—Ü—ñ—ó
"""

import cv2
import time
import argparse
from ultralytics import YOLO
import torch
import numpy as np
from pathlib import Path


def optimize_model(model):
    """–û–ø—Ç–∏–º—ñ–∑–∞—Ü—ñ—è –º–æ–¥–µ–ª—ñ –¥–ª—è —ñ–Ω—Ñ–µ—Ä–µ–Ω—Å—É"""
    # –ü–µ—Ä–µ–∫–ª—é—á–µ–Ω–Ω—è –≤ —Ä–µ–∂–∏–º evaluation
    model.model.eval()
    
    # –í–∏–∫–æ—Ä–∏—Å—Ç–∞–Ω–Ω—è GPU —è–∫—â–æ –¥–æ—Å—Ç—É–ø–Ω–æ
    if torch.cuda.is_available():
        model.model.cuda()
        print(f"‚úì –í–∏–∫–æ—Ä–∏—Å—Ç–æ–≤—É—î—Ç—å—Å—è GPU: {torch.cuda.get_device_name()}")
    else:
        print("‚ö† –í–∏–∫–æ—Ä–∏—Å—Ç–æ–≤—É—î—Ç—å—Å—è CPU")
    
    # –û–ø—Ç–∏–º—ñ–∑–∞—Ü—ñ—è –¥–ª—è —ñ–Ω—Ñ–µ—Ä–µ–Ω—Å—É
    torch.backends.cudnn.benchmark = True
    return model


def test_yolo_video(video_path, model_path="yolov8n.pt", conf_threshold=0.5):
    """
    –¢–µ—Å—Ç—É–≤–∞–Ω–Ω—è YOLO –º–æ–¥–µ–ª—ñ –Ω–∞ –≤—ñ–¥–µ–æ –∑ –º–∞–∫—Å–∏–º–∞–ª—å–Ω–æ—é –æ–ø—Ç–∏–º—ñ–∑–∞—Ü—ñ—î—é
    
    Args:
        video_path: —à–ª—è—Ö –¥–æ –≤—ñ–¥–µ–æ —Ñ–∞–π–ª—É
        model_path: —à–ª—è—Ö –¥–æ YOLO –º–æ–¥–µ–ª—ñ
        conf_threshold: –ø–æ—Ä—ñ–≥ –≤–ø–µ–≤–Ω–µ–Ω–æ—Å—Ç—ñ –¥–ª—è –¥–µ—Ç–µ–∫—Ü—ñ—ó
    """
    
    print(f"üöÄ –ó–∞–≤–∞–Ω—Ç–∞–∂–µ–Ω–Ω—è –º–æ–¥–µ–ª—ñ: {model_path}")
    
    # –ó–∞–≤–∞–Ω—Ç–∞–∂–µ–Ω–Ω—è —Ç–∞ –æ–ø—Ç–∏–º—ñ–∑–∞—Ü—ñ—è –º–æ–¥–µ–ª—ñ
    model = YOLO(model_path)
    model = optimize_model(model)
    
    # –í—ñ–¥–∫—Ä–∏—Ç—Ç—è –≤—ñ–¥–µ–æ
    cap = cv2.VideoCapture(video_path)
    if not cap.isOpened():
        raise ValueError(f"–ù–µ –≤–¥–∞–ª–æ—Å—è –≤—ñ–¥–∫—Ä–∏—Ç–∏ –≤—ñ–¥–µ–æ: {video_path}")
    
    # –û—Ç—Ä–∏–º–∞–Ω–Ω—è –≤–ª–∞—Å—Ç–∏–≤–æ—Å—Ç–µ–π –≤—ñ–¥–µ–æ
    total_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))
    video_fps = cap.get(cv2.CAP_PROP_FPS)
    
    print(f"üìπ –í—ñ–¥–µ–æ: {Path(video_path).name}")
    print(f"   –ö–∞–¥—Ä—ñ–≤: {total_frames}")
    print(f"   FPS –≤—ñ–¥–µ–æ: {video_fps:.1f}")
    print(f"   –ü–æ—Ä—ñ–≥ –≤–ø–µ–≤–Ω–µ–Ω–æ—Å—Ç—ñ: {conf_threshold}")
    print("\nüî• –ü–æ—á–∞—Ç–æ–∫ —Ç–µ—Å—Ç—É–≤–∞–Ω–Ω—è...\n")
    
    # –ó–º—ñ–Ω–Ω—ñ –¥–ª—è –º–µ—Ç—Ä–∏–∫
    frame_times = []
    processed_frames = 0
    total_detections = 0
    
    # –ü–æ—á–∞—Ç–∫–æ–≤–∏–π —á–∞—Å
    start_time = time.time()
    
    try:
        while True:
            ret, frame = cap.read()
            if not ret:
                break
            
            # –ß–∞—Å –ø–æ—á–∞—Ç–∫—É –æ–±—Ä–æ–±–∫–∏ –∫–∞–¥—Ä—É
            frame_start = time.time()
            
            # –Ü–Ω—Ñ–µ—Ä–µ–Ω—Å –±–µ–∑ –∑–±–µ—Ä–µ–∂–µ–Ω–Ω—è —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ñ–≤ –≤—ñ–∑—É–∞–ª—ñ–∑–∞—Ü—ñ—ó
            with torch.no_grad():
                results = model.predict(
                    frame,
                    conf=conf_threshold,
                    verbose=False,  # –í—ñ–¥–∫–ª—é—á–µ–Ω–Ω—è –ª–æ–≥—É–≤–∞–Ω–Ω—è
                    save=False,     # –ù–µ –∑–±–µ—Ä—ñ–≥–∞—Ç–∏ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∏
                    show=False,     # –ù–µ –ø–æ–∫–∞–∑—É–≤–∞—Ç–∏
                    stream=False    # –ù–µ –≤–∏–∫–æ—Ä–∏—Å—Ç–æ–≤—É–≤–∞—Ç–∏ —Å—Ç—Ä—ñ–º —Ä–µ–∂–∏–º
                )
            
            # –ü—ñ–¥—Ä–∞—Ö—É–Ω–æ–∫ –¥–µ—Ç–µ–∫—Ü—ñ–π (–æ–ø—Ü—ñ–æ–Ω–∞–ª—å–Ω–æ)
            if results and len(results) > 0:
                total_detections += len(results[0].boxes) if results[0].boxes is not None else 0
            
            # –ß–∞—Å –∑–∞–≤–µ—Ä—à–µ–Ω–Ω—è –æ–±—Ä–æ–±–∫–∏ –∫–∞–¥—Ä—É
            frame_end = time.time()
            frame_time = frame_end - frame_start
            frame_times.append(frame_time)
            
            processed_frames += 1
            
            # –ü—Ä–æ–≥—Ä–µ—Å—Å –∫–æ–∂–Ω—ñ 100 –∫–∞–¥—Ä—ñ–≤
            if processed_frames % 100 == 0:
                current_fps = 1.0 / np.mean(frame_times[-100:])
                print(f"–ö–∞–¥—Ä {processed_frames}/{total_frames} | FPS: {current_fps:.1f}")
    
    except KeyboardInterrupt:
        print("\n‚ö† –¢–µ—Å—Ç—É–≤–∞–Ω–Ω—è –ø–µ—Ä–µ—Ä–≤–∞–Ω–æ –∫–æ—Ä–∏—Å—Ç—É–≤–∞—á–µ–º")
    
    finally:
        cap.release()
    
    # –ü—ñ–¥—Ä–∞—Ö—É–Ω–æ–∫ —Ñ—ñ–Ω–∞–ª—å–Ω–∏—Ö –º–µ—Ç—Ä–∏–∫
    total_time = time.time() - start_time
    
    if frame_times:
        avg_frame_time = np.mean(frame_times)
        avg_fps = 1.0 / avg_frame_time
        min_frame_time = np.min(frame_times)
        max_frame_time = np.max(frame_times)
        std_frame_time = np.std(frame_times)
    else:
        avg_frame_time = avg_fps = min_frame_time = max_frame_time = std_frame_time = 0
    
    # –í–∏–≤–µ–¥–µ–Ω–Ω—è —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ñ–≤
    print("\n" + "="*60)
    print("üìä –†–ï–ó–£–õ–¨–¢–ê–¢–ò –¢–ï–°–¢–£–í–ê–ù–ù–Ø")
    print("="*60)
    print(f"–û–±—Ä–æ–±–ª–µ–Ω–æ –∫–∞–¥—Ä—ñ–≤:           {processed_frames}")
    print(f"–ó–∞–≥–∞–ª—å–Ω–∏–π —á–∞—Å:              {total_time:.2f} —Å–µ–∫")
    print(f"–°–µ—Ä–µ–¥–Ω—ñ–π FPS:               {avg_fps:.2f}")
    print(f"–°–µ—Ä–µ–¥–Ω—ñ–π —á–∞—Å –∫–∞–¥—Ä—É:         {avg_frame_time*1000:.2f} –º—Å")
    print(f"–ú—ñ–Ω —á–∞—Å –∫–∞–¥—Ä—É:              {min_frame_time*1000:.2f} –º—Å")
    print(f"–ú–∞–∫—Å —á–∞—Å –∫–∞–¥—Ä—É:             {max_frame_time*1000:.2f} –º—Å")
    print(f"–°—Ç–∞–Ω–¥–∞—Ä—Ç–Ω–µ –≤—ñ–¥—Ö–∏–ª–µ–Ω–Ω—è:      {std_frame_time*1000:.2f} –º—Å")
    print(f"–ó–∞–≥–∞–ª—å–Ω–∞ –∫—ñ–ª—å–∫—ñ—Å—Ç—å –¥–µ—Ç–µ–∫—Ü—ñ–π: {total_detections}")
    print(f"–°–µ—Ä–µ–¥–Ω—å–æ –¥–µ—Ç–µ–∫—Ü—ñ–π –Ω–∞ –∫–∞–¥—Ä:  {total_detections/processed_frames:.1f}")
    
    # –ü–æ—Ä—ñ–≤–Ω—è–Ω–Ω—è –∑ —Ä–µ–∞–ª—å–Ω–∏–º FPS –≤—ñ–¥–µ–æ
    if video_fps > 0:
        realtime_ratio = avg_fps / video_fps
        print(f"–ö–æ–µ—Ñ—ñ—Ü—ñ—î–Ω—Ç —Ä–µ–∞–ª—å–Ω–æ–≥–æ —á–∞—Å—É:  {realtime_ratio:.2f}x")
        if realtime_ratio >= 1.0:
            print("‚úÖ –û–±—Ä–æ–±–∫–∞ –≤ —Ä–µ–∞–ª—å–Ω–æ–º—É —á–∞—Å—ñ –¥–æ—Å—è–≥–Ω—É—Ç–∞!")
        else:
            print("‚ö† –û–±—Ä–æ–±–∫–∞ –ø–æ–≤—ñ–ª—å–Ω—ñ—à–µ —Ä–µ–∞–ª—å–Ω–æ–≥–æ —á–∞—Å—É")


def main():
    parser = argparse.ArgumentParser(description="YOLO –≤—ñ–¥–µ–æ —Ç–µ—Å—Ç –ø—Ä–æ–¥—É–∫—Ç–∏–≤–Ω–æ—Å—Ç—ñ")
    parser.add_argument("video", help="–®–ª—è—Ö –¥–æ –≤—ñ–¥–µ–æ —Ñ–∞–π–ª—É")
    parser.add_argument("-m", "--model", default="yolov8n.pt", 
                       help="–®–ª—è—Ö –¥–æ YOLO –º–æ–¥–µ–ª—ñ (–∑–∞ –∑–∞–º–æ–≤—á—É–≤–∞–Ω–Ω—è–º: yolov8n.pt)")
    parser.add_argument("-c", "--conf", type=float, default=0.5,
                       help="–ü–æ—Ä—ñ–≥ –≤–ø–µ–≤–Ω–µ–Ω–æ—Å—Ç—ñ (–∑–∞ –∑–∞–º–æ–≤—á—É–≤–∞–Ω–Ω—è–º: 0.5)")
    
    args = parser.parse_args()
    
    # –ü–µ—Ä–µ–≤—ñ—Ä–∫–∞ —ñ—Å–Ω—É–≤–∞–Ω–Ω—è —Ñ–∞–π–ª—ñ–≤
    if not Path(args.video).exists():
        print(f"‚ùå –í—ñ–¥–µ–æ —Ñ–∞–π–ª –Ω–µ –∑–Ω–∞–π–¥–µ–Ω–æ: {args.video}")
        return
    
    try:
        test_yolo_video(args.video, args.model, args.conf)
    except Exception as e:
        print(f"‚ùå –ü–æ–º–∏–ª–∫–∞: {e}")


if __name__ == "__main__":
    # –ü—Ä–∏–∫–ª–∞–¥ –≤–∏–∫–æ—Ä–∏—Å—Ç–∞–Ω–Ω—è –±–µ–∑ –∞—Ä–≥—É–º–µ–Ω—Ç—ñ–≤ –∫–æ–º–∞–Ω–¥–Ω–æ–≥–æ —Ä—è–¥–∫–∞
    # –ó–∞–º—ñ–Ω—ñ—Ç—å –Ω–∞ –≤–∞—à—ñ —à–ª—è—Ö–∏
    VIDEO_PATH = "D:\\diplom\\video_and_photo\\BMP.MP4"  # –ó–∞–º—ñ–Ω—ñ—Ç—å –Ω–∞ —Å–≤—ñ–π –≤—ñ–¥–µ–æ —Ñ–∞–π–ª
    MODEL_PATH = "D:\\diplom\\YOLO_final_training_best_model\\yolo11n_SGD(0_001)\\weights\\yolo11n_SGD(0_001).pt"      # –ú–æ–∂–Ω–∞ –∑–º—ñ–Ω–∏—Ç–∏ –Ω–∞ yolov8s.pt, yolov8m.pt, —Ç–æ—â–æ
    
    if Path(VIDEO_PATH).exists():
        test_yolo_video(VIDEO_PATH, MODEL_PATH, conf_threshold=0.5)
    else:
        print("–î–ª—è –∑–∞–ø—É—Å–∫—É —Å–∫—Ä–∏–ø—Ç–∞:")
        print("python script.py your_video.mp4 -m yolov8n.pt -c 0.5")
        print("\n–ê–±–æ –∑–∞–º—ñ–Ω—ñ—Ç—å VIDEO_PATH —É –∫–æ–¥—ñ –Ω–∞ –≤–∞—à –≤—ñ–¥–µ–æ —Ñ–∞–π–ª")